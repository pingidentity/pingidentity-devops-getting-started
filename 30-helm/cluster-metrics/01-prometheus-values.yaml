#### "TESTED ON: Chart version: 57.2.0  App Version: 0.72.0"
##    Deployed with:
## helm upgrade --install metrics prometheus-community/kube-prometheus-stack -f 01-prometheus-values.yaml -n metrics --version 57.2.0
##

## Override the deployment namespace
##
namespaceOverride: "metrics"

## Install Prometheus Operator CRDs
##
crds:
  enabled: true

## Create default rules for monitoring the cluster
##
defaultRules:
  create: true
  rules:
    alertmanager: true
    etcd: true
    configReloaders: true
    general: true
    k8sContainerCpuUsageSecondsTotal: true
    k8sContainerMemoryCache: true
    k8sContainerMemoryRss: true
    k8sContainerMemorySwap: true
    k8sContainerResource: true
    k8sContainerMemoryWorkingSetBytes: true
    k8sPodOwner: true
    kubeApiserverAvailability: true
    kubeApiserverBurnrate: true
    kubeApiserverHistogram: true
    kubeApiserverSlos: true
    kubeControllerManager: true
    kubelet: true
    kubeProxy: true
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    kubeSchedulerAlerting: true
    kubeSchedulerRecording: true
    kubeStateMetrics: true
    network: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true

##
global:
  rbac:
    create: true
    createAggregateClusterRoles: false
    pspEnabled: true
    pspAnnotations: {}

## Configuration for alertmanager
## ref: https://prometheus.io/docs/alerting/alertmanager/
##
alertmanager:
  enabled: true
  apiVersion: v2
  serviceAccount:
    create: true
    name: ""
    annotations: {}
    automountServiceAccountToken: true
  ingress:
    enabled: false
    annotations: {}
    spec:
      # Must match the name of the IngressClass resource
      ingressClassName: nginx
    labels: {}
    ## CHANGEME
    hosts:
      - alertmanager-mymetrics.pingdemo.example
    paths:
      - /
    tls: []
  secret:
    annotations: {}
    tlsSecretName: ""

## Deploy Grafana
##
grafana:
  enabled: true
  defaultDashboardsEnabled: true

  ## CHANGEME
  defaultDashboardsTimezone: America/Chicago
  defaultDashboardsEditable: true
  ## CHANGEME
  adminPassword: prom-operator
  rbac:
    pspEnabled: false
  ingress:
    enabled: truez
    ingressClassName: nginx
    spec:
      ingressClassName: nginx
    annotations: {}
    labels: {}
    hosts:
      - grafana-mymetrics.pingdemo.example
    path: /
    tls: []
  serviceAccount:
    create: true
    autoMount: true

  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
      labelValue: "1"
      # Allow discovery in all namespaces for dashboards
      searchNamespace: ALL
      enableNewTablePanelSyntax: true
      annotations: {}
      multicluster:
        global:
          enabled: false
        etcd:
          enabled: false
      provider:
        allowUiUpdates: false
    datasources:
      enabled: true
      defaultDatasourceEnabled: true
      isDefaultDatasource: true

      uid: prometheus
      annotations: {}
      httpMethod: POST
      exemplarTraceIdDestinations: {}
      alertmanager:
        enabled: true
        uid: alertmanager
        handleGrafanaManagedAlerts: false
        implementation: prometheus

  ## Passed to grafana subchart and used by servicemonitor below
  ##
  service:
    portName: http-web

  serviceMonitor:
    enabled: true
    path: "/metrics"
    labels: {}
    interval: ""
    scheme: http
    tlsConfig: {}
    scrapeTimeout: 30s
    relabelings: []

## Flag to disable all the kubernetes component scrapers
##
kubernetesServiceMonitors:
  enabled: true

## Component scraping the kube api server
##
kubeApiServer:
  enabled: true
  tlsConfig:
    serverName: kubernetes
    insecureSkipVerify: false
  serviceMonitor:
    interval: ""
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    proxyUrl: ""

    jobLabel: component
    selector:
      matchLabels:
        component: apiserver
        provider: kubernetes

    metricRelabelings:
      # Drop excessively noisy apiserver buckets.
      - action: drop
        regex: apiserver_request_duration_seconds_bucket;(0.15|0.2|0.3|0.35|0.4|0.45|0.6|0.7|0.8|0.9|1.25|1.5|1.75|2|3|3.5|4|4.5|6|7|8|9|15|25|40|50)
        sourceLabels:
          - __name__
          - le
    relabelings: []
    additionalLabels: {}

## Component scraping the kubelet and kubelet-hosted cAdvisor
##
kubelet:
  enabled: true
  namespace: kube-system

  serviceMonitor:
    attachMetadata:
      node: false
    interval: ""
    honorLabels: true
    honorTimestamps: true
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    proxyUrl: ""
    https: true
    cAdvisor: true
    probes: true
    resource: false
    resourcePath: "/metrics/resource/v1alpha1"

    cAdvisorMetricRelabelings:
      # Drop less useful container CPU metrics.
      - sourceLabels: [__name__]
        action: drop
        regex: "container_cpu_(cfs_throttled_seconds_total|load_average_10s|system_seconds_total|user_seconds_total)"
      # Drop less useful container / always zero filesystem metrics.
      - sourceLabels: [__name__]
        action: drop
        regex: "container_fs_(io_current|io_time_seconds_total|io_time_weighted_seconds_total|reads_merged_total|sector_reads_total|sector_writes_total|writes_merged_total)"
      # Drop less useful / always zero container memory metrics.
      - sourceLabels: [__name__]
        action: drop
        regex: "container_memory_(mapped_file|swap)"
      # Drop less useful container process metrics.
      - sourceLabels: [__name__]
        action: drop
        regex: "container_(file_descriptors|tasks_state|threads_max)"
      # Drop container spec metrics that overlap with kube-state-metrics.
      - sourceLabels: [__name__]
        action: drop
        regex: "container_spec.*"
      # Drop cgroup metrics with no pod.
      - sourceLabels: [id, pod]
        action: drop
        regex: ".+;"
    probesMetricRelabelings: []
    cAdvisorRelabelings:
      - action: replace
        sourceLabels: [__metrics_path__]
        targetLabel: metrics_path
    probesRelabelings:
      - action: replace
        sourceLabels: [__metrics_path__]
        targetLabel: metrics_path
    resourceRelabelings:
      - action: replace
        sourceLabels: [__metrics_path__]
        targetLabel: metrics_path
    metricRelabelings: []
    relabelings:
      - action: replace
        sourceLabels: [__metrics_path__]
        targetLabel: metrics_path
    additionalLabels: {}

## Component scraping the kube controller manager
##
kubeControllerManager:
  enabled: true
  endpoints: []
  service:
    enabled: true
    port: null
    targetPort: null

  serviceMonitor:
    enabled: true
    interval: ""
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    proxyUrl: ""
    port: metrics
    jobLabel: jobLabel
    selector: {}
    https: null
    insecureSkipVerify: null
    serverName: null
    metricRelabelings: []
    relabelings: []
    additionalLabels: {}

## Component scraping coreDns. Use either this or kubeDns
##
coreDns:
  enabled: true
  service:
    enabled: true
    port: 9153
    targetPort: 9153
    # selector:
    #   k8s-app: kube-dns
  serviceMonitor:
    enabled: true
    interval: ""
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    proxyUrl: ""
    port: metrics
    jobLabel: jobLabel
    selector: {}
    metricRelabelings: []
    relabelings: []
    additionalLabels: {}

## Component scraping kubeDns. Use either this or coreDns
##
kubeDns:
  enabled: false
  service:
    dnsmasq:
      port: 10054
      targetPort: 10054
    skydns:
      port: 10055
      targetPort: 10055
    # selector:
    #   k8s-app: kube-dns
  serviceMonitor:
    interval: ""
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    proxyUrl: ""
    jobLabel: jobLabel
    selector: {}
    metricRelabelings: []
    relabelings: []
    dnsmasqMetricRelabelings: []
    dnsmasqRelabelings: []
    additionalLabels: {}

## Component scraping etcd
##
kubeEtcd:
  enabled: true
  endpoints: []
  service:
    enabled: true
    port: 2381
    targetPort: 2381
    # selector:
    #   component: etcd

  serviceMonitor:
    enabled: true
    interval: ""
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    proxyUrl: ""
    scheme: http
    insecureSkipVerify: false
    serverName: ""
    caFile: ""
    certFile: ""
    keyFile: ""
    port: metrics
    jobLabel: jobLabel
    selector: {}
    metricRelabelings: []
    relabelings: []
    additionalLabels: {}

## Component scraping kube scheduler
##
kubeScheduler:
  enabled: true
  endpoints: []
  service:
    enabled: true
    port: null
    targetPort: null

  serviceMonitor:
    enabled: true
    interval: ""
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    proxyUrl: ""
    https: null
    port: metrics
    jobLabel: jobLabel
    selector: {}
    insecureSkipVerify: null
    serverName: null
    metricRelabelings: []
    relabelings: []
    additionalLabels: {}

## Component scraping kube proxy
##
kubeProxy:
  enabled: true
  endpoints: []
  service:
    enabled: true
    port: 10249
    targetPort: 10249
  serviceMonitor:
    enabled: true
    interval: ""
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    proxyUrl: ""
    port: metrics
    jobLabel: jobLabel
    selector: {}
    https: false
    metricRelabelings: []
    relabelings: []
    additionalLabels: {}

## Component scraping kube state metrics
##
kubeStateMetrics:
  enabled: true

kube-state-metrics:
  namespaceOverride: ""
  rbac:
    create: true
  releaseLabel: true
  prometheus:
    monitor:
      enabled: true
      interval: ""
      sampleLimit: 0
      targetLimit: 0
      labelLimit: 0
      labelNameLengthLimit: 0
      labelValueLengthLimit: 0
      scrapeTimeout: ""
      proxyUrl: ""
      honorLabels: true
      metricRelabelings: []
      relabelings: []
  selfMonitor:
    enabled: false

## Deploy node exporter as a daemonset to all nodes
##
nodeExporter:
  enabled: true
  operatingSystems:
    linux:
      enabled: true
    darwin:
      enabled: true
  forceDeployDashboards: false

## Configuration for prometheus-node-exporter subchart
##
prometheus-node-exporter:
  namespaceOverride: ""
  ## CHANGEME
  ## hostRootFsMount 'false' is a workaround for Docker-Desktop on Mac
  ## Not needed on Linux hosts
  # hostRootFsMount:
  #   enabled: false
  podLabels:
    ## Add the 'node-exporter' label to be used by serviceMonitor to match standard common usage in rules and grafana dashboards
    ##
    jobLabel: node-exporter
  releaseLabel: true
  extraArgs:
    - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
    - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
  service:
    portName: http-metrics
  prometheus:
    monitor:
      enabled: true
      jobLabel: jobLabel
      interval: ""
      sampleLimit: 0
      targetLimit: 0
      labelLimit: 0
      labelNameLengthLimit: 0
      labelValueLengthLimit: 0
      scrapeTimeout: ""
      proxyUrl: ""
      metricRelabelings: []
      relabelings: []
  rbac:
    pspEnabled: false

## Manages Prometheus and Alertmanager components
##
prometheusOperator:
  enabled: true
  fullnameOverride: ""
  revisionHistoryLimit: 10
  strategy: {}
  tls:
    enabled: true
    # Value must match version names from https://golang.org/pkg/crypto/tls/#pkg-constants
    tlsMinVersion: VersionTLS13
    # The default webhook port is 10250 in order to work out-of-the-box in GKE private clusters and avoid adding firewall rules.
    internalPort: 10250

  admissionWebhooks:
    failurePolicy: ""
    timeoutSeconds: 10
    enabled: true
    caBundle: ""
    annotations: {}
    namespaceSelector: {}
    deployment:
      enabled: false
      replicas: 1
      strategy: {}
      podDisruptionBudget: {}
      revisionHistoryLimit: 10
      tls:
        enabled: true
        tlsMinVersion: VersionTLS13
        internalPort: 10250
      serviceAccount:
        automountServiceAccountToken: false
        create: true
        name: ""

      ## Configuration for Prometheus operator Webhook service
      ##
      service:
        annotations: {}
        labels: {}
        clusterIP: ""
        nodePort: 31080
        nodePortTls: 31443
        additionalPorts: []
        loadBalancerIP: ""
        loadBalancerSourceRanges: []
        externalTrafficPolicy: Cluster
        type: ClusterIP
        externalIPs: []
      labels: {}
      annotations: {}
      podLabels: {}
      podAnnotations: {}
      image:
        registry: quay.io
        repository: prometheus-operator/admission-webhook
        # if not set appVersion field from Chart.yaml is used
        tag: ""
        sha: ""
        pullPolicy: IfNotPresent
      livenessProbe:
        enabled: true
        failureThreshold: 3
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1

      ## Readiness probe
      ##
      readinessProbe:
        enabled: true
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      hostNetwork: false
      nodeSelector: {}
      tolerations: []
      affinity: {}
      dnsConfig: {}
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
        seccompProfile:
          type: RuntimeDefault
      containerSecurityContext:
        allowPrivilegeEscalation: false
        readOnlyRootFilesystem: true
        capabilities:
          drop:
            - ALL
      automountServiceAccountToken: true

    patch:
      enabled: true
      image:
        registry: registry.k8s.io
        repository: ingress-nginx/kube-webhook-certgen
        tag: v20221220-controller-v1.5.1-58-g787ea74b6
        sha: ""
        pullPolicy: IfNotPresent
      resources: {}
      ## Provide a priority class name to the webhook patching job
      ##
      priorityClassName: ""
      annotations: {}
      podAnnotations: {}
      nodeSelector: {}
      affinity: {}
      tolerations: []
      securityContext:
        runAsGroup: 2000
        runAsNonRoot: true
        runAsUser: 2000
        seccompProfile:
          type: RuntimeDefault
    createSecretJob:
      securityContext:
        allowPrivilegeEscalation: false
        readOnlyRootFilesystem: true
        capabilities:
          drop:
            - ALL
    patchWebhookJob:
      securityContext:
        allowPrivilegeEscalation: false
        readOnlyRootFilesystem: true
        capabilities:
          drop:
            - ALL
    certManager:
      enabled: false
      rootCert:
        duration: "" # default to be 5y
      admissionCert:
        duration: "" # default to be 1y
  namespaces: {}
  denyNamespaces: []
  alertmanagerInstanceNamespaces: []
  alertmanagerConfigNamespaces: []
  prometheusInstanceNamespaces: []
  thanosRulerInstanceNamespaces: []

  networkPolicy:
    enabled: false
    flavor: kubernetes
  serviceAccount:
    create: true
    name: ""
    automountServiceAccountToken: true

  ## Configuration for Prometheus operator service
  ##
  service:
    annotations: {}
    labels: {}
    clusterIP: ""
    nodePort: 30080
    nodePortTls: 30443
    additionalPorts: []
    loadBalancerIP: ""
    loadBalancerSourceRanges: []
    externalTrafficPolicy: Cluster
    type: ClusterIP
    externalIPs: []
  labels: {}
  annotations: {}
  podLabels: {}
  podAnnotations: {}
  kubeletService:
    enabled: true
    namespace: kube-system
    name: ""

  ## Create a servicemonitor for the operator
  ##
  serviceMonitor:
    selfMonitor: true
    additionalLabels: {}
    interval: ""
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    scrapeTimeout: ""
    metricRelabelings: []
    relabelings: []
  resources: {}
  env:
    GOGC: "30"
  hostNetwork: false
  nodeSelector: {}
  tolerations: []
  affinity: {}
  dnsConfig: {}
  securityContext:
    fsGroup: 65534
    runAsGroup: 65534
    runAsNonRoot: true
    runAsUser: 65534
    seccompProfile:
      type: RuntimeDefault
  containerSecurityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL
    # updatePolicy:
    #   updateMode: Auto

  ## Prometheus-operator image
  ##
  image:
    registry: quay.io
    repository: prometheus-operator/prometheus-operator
    # if not set appVersion field from Chart.yaml is used
    tag: ""
    sha: ""
    pullPolicy: IfNotPresent

  prometheusConfigReloader:
    image:
      registry: quay.io
      repository: prometheus-operator/prometheus-config-reloader
      # if not set appVersion field from Chart.yaml is used
      tag: ""
      sha: ""

    enableProbe: false

    resources: {}

  ## Thanos side-car image when configured
  ##
  thanosImage:
    registry: quay.io
    repository: thanos/thanos
    tag: v0.34.1
    sha: ""

  ## Set a Label Selector to filter watched prometheus and prometheusAgent
  ##
  prometheusInstanceSelector: ""

  ## Set a Label Selector to filter watched alertmanager
  ##
  alertmanagerInstanceSelector: ""

  ## Set a Label Selector to filter watched thanosRuler
  thanosRulerInstanceSelector: ""

  ## Set a Field Selector to filter watched secrets
  ##
  secretFieldSelector: "type!=kubernetes.io/dockercfg,type!=kubernetes.io/service-account-token,type!=helm.sh/release.v1"

  ## If false then the user will opt out of automounting API credentials.
  ##
  automountServiceAccountToken: true

  ## Additional volumes
  ##
  extraVolumes: []

  ## Additional volume mounts
  ##
  extraVolumeMounts: []

## Deploy a Prometheus instance
##
prometheus:
  enabled: true

  ## Toggle prometheus into agent mode
  ## Note many of features described below (e.g. rules, query, alerting, remote read, thanos) will not work in agent mode.
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/designs/prometheus-agent.md
  ##
  agentMode: false

  ## Annotations for Prometheus
  ##
  annotations: {}

  ## Configure network policy for the prometheus
  networkPolicy:
    enabled: false

    ## Flavor of the network policy to use.
    #  Can be:
    #  * kubernetes for networking.k8s.io/v1/NetworkPolicy
    #  * cilium     for cilium.io/v2/CiliumNetworkPolicy
    flavor: kubernetes

    # cilium:
    #   endpointSelector:
    #   egress:
    #   ingress:

    # egress:
    # - {}
    # ingress:
    # - {}
    # podSelector:
    #   matchLabels:
    #     app: prometheus

  ## Service account for Prometheuses to use.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
  ##
  serviceAccount:
    create: true
    name: ""
    annotations: {}
    automountServiceAccountToken: true

  # Service for thanos service discovery on sidecar
  # Enable this can make Thanos Query can use
  # `--store=dnssrv+_grpc._tcp.${kube-prometheus-stack.fullname}-thanos-discovery.${namespace}.svc.cluster.local` to discovery
  # Thanos sidecar on prometheus nodes
  # (Please remember to change ${kube-prometheus-stack.fullname} and ${namespace}. Not just copy and paste!)
  thanosService:
    enabled: false
    annotations: {}
    labels: {}

    ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints
    ##
    externalTrafficPolicy: Cluster

    ## Service type
    ##
    type: ClusterIP

    ## gRPC port config
    portName: grpc
    port: 10901
    targetPort: "grpc"

    ## HTTP port config (for metrics)
    httpPortName: http
    httpPort: 10902
    targetHttpPort: "http"

    ## ClusterIP to assign
    # Default is to make this a headless service ("None")
    clusterIP: "None"

    ## Port to expose on each node, if service type is NodePort
    ##
    nodePort: 30901
    httpNodePort: 30902

  # ServiceMonitor to scrape Sidecar metrics
  # Needs thanosService to be enabled as well
  thanosServiceMonitor:
    enabled: false
    interval: ""

    ## Additional labels
    ##
    additionalLabels: {}

    ## scheme: HTTP scheme to use for scraping. Can be used with `tlsConfig` for example if using istio mTLS.
    scheme: ""

    ## tlsConfig: TLS configuration to use when scraping the endpoint. For example if using istio mTLS.
    ## Of type: https://github.com/coreos/prometheus-operator/blob/main/Documentation/api.md#tlsconfig
    tlsConfig: {}

    bearerTokenFile:

    ## Metric relabel configs to apply to samples before ingestion.
    metricRelabelings: []

    ## relabel configs to apply to samples before ingestion.
    relabelings: []

  # Service for external access to sidecar
  # Enabling this creates a service to expose thanos-sidecar outside the cluster.
  thanosServiceExternal:
    enabled: false
    annotations: {}
    labels: {}
    loadBalancerIP: ""
    loadBalancerSourceRanges: []

    ## gRPC port config
    portName: grpc
    port: 10901
    targetPort: "grpc"

    ## HTTP port config (for metrics)
    httpPortName: http
    httpPort: 10902
    targetHttpPort: "http"

    ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints
    ##
    externalTrafficPolicy: Cluster

    ## Service type
    ##
    type: LoadBalancer

    ## Port to expose on each node
    ##
    nodePort: 30901
    httpNodePort: 30902

  ## Configuration for Prometheus service
  ##
  service:
    annotations: {}
    labels: {}
    clusterIP: ""

    ## Port for Prometheus Service to listen on
    ##
    port: 9090

    ## To be used with a proxy extraContainer port
    targetPort: 9090

    ## Port for Prometheus Reloader to listen on
    ##
    reloaderWebPort: 8080

    ## List of IP addresses at which the Prometheus server service is available
    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips
    ##
    externalIPs: []

    ## Port to expose on each node
    ## Only used if service.type is 'NodePort'
    ##
    nodePort: 30090

    ## Loadbalancer IP
    ## Only use if service.type is "LoadBalancer"
    loadBalancerIP: ""
    loadBalancerSourceRanges: []

    ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints
    ##
    externalTrafficPolicy: Cluster

    ## Service type
    ##
    type: ClusterIP

    ## Additional ports to open for Prometheus service
    ##
    additionalPorts: []
    # additionalPorts:
    # - name: oauth-proxy
    #   port: 8081
    #   targetPort: 8081
    # - name: oauth-metrics
    #   port: 8082
    #   targetPort: 8082

    ## Consider that all endpoints are considered "ready" even if the Pods themselves are not
    ## Ref: https://kubernetes.io/docs/reference/kubernetes-api/service-resources/service-v1/#ServiceSpec
    publishNotReadyAddresses: false

    ## If you want to make sure that connections from a particular client are passed to the same Pod each time
    ## Accepts 'ClientIP' or 'None'
    ##
    sessionAffinity: None

    ## If you want to modify the ClientIP sessionAffinity timeout
    ## The value must be >0 && <=86400(for 1 day) if ServiceAffinity == "ClientIP"
    ##
    sessionAffinityConfig:
      clientIP:
        timeoutSeconds: 10800

  ## Configuration for creating a separate Service for each statefulset Prometheus replica
  ##
  servicePerReplica:
    enabled: false
    annotations: {}

    ## Port for Prometheus Service per replica to listen on
    ##
    port: 9090

    ## To be used with a proxy extraContainer port
    targetPort: 9090

    ## Port to expose on each node
    ## Only used if servicePerReplica.type is 'NodePort'
    ##
    nodePort: 30091

    ## Loadbalancer source IP ranges
    ## Only used if servicePerReplica.type is "LoadBalancer"
    loadBalancerSourceRanges: []

    ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints
    ##
    externalTrafficPolicy: Cluster

    ## Service type
    ##
    type: ClusterIP

  ## Configure pod disruption budgets for Prometheus
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/#specifying-a-poddisruptionbudget
  ##
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
    maxUnavailable: ""

  # Ingress exposes thanos sidecar outside the cluster
  thanosIngress:
    enabled: false

    # For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName
    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
    # ingressClassName: nginx

    annotations: {}
    labels: {}
    servicePort: 10901

    ## Port to expose on each node
    ## Only used if service.type is 'NodePort'
    ##
    nodePort: 30901

    ## Hosts must be provided if Ingress is enabled.
    ##
    hosts:
      []
      # - thanos-gateway.domain.com

    ## Paths to use for ingress rules
    ##
    paths: []
    # - /

    ## For Kubernetes >= 1.18 you should specify the pathType (determines how Ingress paths should be matched)
    ## See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#better-path-matching-with-path-types
    # pathType: ImplementationSpecific

    ## TLS configuration for Thanos Ingress
    ## Secret must be manually created in the namespace
    ##
    tls: []
    # - secretName: thanos-gateway-tls
    #   hosts:
    #   - thanos-gateway.domain.com
    #

  ## ExtraSecret can be used to store various data in an extra secret
  ## (use it for example to store hashed basic auth credentials)
  extraSecret:
    ## if not set, name will be auto generated
    # name: ""
    annotations: {}
    data: {}
  #   auth: |
  #     foo:$apr1$OFG3Xybp$ckL0FHDAkoXYIlH9.cysT0
  #     someoneelse:$apr1$DMZX2Z4q$6SbQIfyuLQd.xmo/P0m2c.

  ingress:
    enabled: false

    # For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName
    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
    # ingressClassName: nginx

    annotations: {}
    labels: {}

    ## Redirect ingress to an additional defined port on the service
    # servicePort: 8081

    ## Hostnames.
    ## Must be provided if Ingress is enabled.
    ##
    # hosts:
    #   - prometheus.domain.com
    hosts: []

    ## Paths to use for ingress rules - one path should match the prometheusSpec.routePrefix
    ##
    paths: []
    # - /

    ## For Kubernetes >= 1.18 you should specify the pathType (determines how Ingress paths should be matched)
    ## See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#better-path-matching-with-path-types
    # pathType: ImplementationSpecific

    ## TLS configuration for Prometheus Ingress
    ## Secret must be manually created in the namespace
    ##
    tls:
      []
      # - secretName: prometheus-general-tls
      #   hosts:
      #     - prometheus.example.com

  ## Configuration for creating an Ingress that will map to each Prometheus replica service
  ## prometheus.servicePerReplica must be enabled
  ##
  ingressPerReplica:
    enabled: false

    # For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName
    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
    # ingressClassName: nginx

    annotations: {}
    labels: {}

    ## Final form of the hostname for each per replica ingress is
    ## {{ ingressPerReplica.hostPrefix }}-{{ $replicaNumber }}.{{ ingressPerReplica.hostDomain }}
    ##
    ## Prefix for the per replica ingress that will have `-$replicaNumber`
    ## appended to the end
    hostPrefix: ""
    ## Domain that will be used for the per replica ingress
    hostDomain: ""

    ## Paths to use for ingress rules
    ##
    paths: []
    # - /

    ## For Kubernetes >= 1.18 you should specify the pathType (determines how Ingress paths should be matched)
    ## See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#better-path-matching-with-path-types
    # pathType: ImplementationSpecific

    ## Secret name containing the TLS certificate for Prometheus per replica ingress
    ## Secret must be manually created in the namespace
    tlsSecretName: ""

    ## Separated secret for each per replica Ingress. Can be used together with cert-manager
    ##
    tlsSecretPerReplica:
      enabled: false
      ## Final form of the secret for each per replica ingress is
      ## {{ tlsSecretPerReplica.prefix }}-{{ $replicaNumber }}
      ##
      prefix: "prometheus"

  ## Configure additional options for default pod security policy for Prometheus
  ## ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/
  podSecurityPolicy:
    allowedCapabilities: []
    allowedHostPaths: []
    volumes: []

  serviceMonitor:
    ## If true, create a serviceMonitor for prometheus
    ##
    selfMonitor: true

    ## Scrape interval. If not set, the Prometheus default scrape interval is used.
    ##
    interval: ""

    ## Additional labels
    ##
    additionalLabels: {}

    ## SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.
    ##
    sampleLimit: 0

    ## TargetLimit defines a limit on the number of scraped targets that will be accepted.
    ##
    targetLimit: 0

    ## Per-scrape limit on number of labels that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.
    ##
    labelLimit: 0

    ## Per-scrape limit on length of labels name that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.
    ##
    labelNameLengthLimit: 0

    ## Per-scrape limit on length of labels value that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.
    ##
    labelValueLengthLimit: 0

    ## scheme: HTTP scheme to use for scraping. Can be used with `tlsConfig` for example if using istio mTLS.
    scheme: ""

    ## tlsConfig: TLS configuration to use when scraping the endpoint. For example if using istio mTLS.
    ## Of type: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#tlsconfig
    tlsConfig: {}

    bearerTokenFile:

    ## Metric relabel configs to apply to samples before ingestion.
    ##
    metricRelabelings: []
    # - action: keep
    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'
    #   sourceLabels: [__name__]

    #   relabel configs to apply to samples before ingestion.
    ##
    relabelings: []
    # - sourceLabels: [__meta_kubernetes_pod_node_name]
    #   separator: ;
    #   regex: ^(.*)$
    #   targetLabel: nodename
    #   replacement: $1
    #   action: replace

    ## Additional Endpoints
    ##
    additionalEndpoints: []
    # - port: oauth-metrics
    #   path: /metrics

  ## Settings affecting prometheusSpec
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#prometheusspec
  ##
  prometheusSpec:
    disableCompaction: false
    apiserverConfig: {}
    additionalArgs: []
    scrapeInterval: ""
    scrapeTimeout: ""
    evaluationInterval: ""
    listenLocal: false
    enableAdminAPI: false
    version: ""
    web: {}
    exemplars: ""
    enableFeatures: []
    image:
      registry: quay.io
      repository: prometheus/prometheus
      tag: v2.51.0
      sha: ""
    tolerations: []
    topologySpreadConstraints: []
    alertingEndpoints: []
    externalLabels: {}
    enableRemoteWriteReceiver: false
    replicaExternalLabelName: ""
    replicaExternalLabelNameClear: false
    prometheusExternalLabelName: ""
    prometheusExternalLabelNameClear: false
    externalUrl: ""
    nodeSelector: {}
    secrets: []
    configMaps: []
    query: {}
    ruleNamespaceSelector: {}
    ruleSelectorNilUsesHelmValues: true
    ruleSelector: {}
    serviceMonitorSelectorNilUsesHelmValues: true
    serviceMonitorSelector: {}
    serviceMonitorNamespaceSelector: {}
    podMonitorSelectorNilUsesHelmValues: true
    podMonitorSelector: {}
    podMonitorNamespaceSelector: {}
    probeSelectorNilUsesHelmValues: true
    probeSelector: {}
    probeNamespaceSelector: {}
    scrapeConfigSelectorNilUsesHelmValues: true
    scrapeConfigSelector: {}
    scrapeConfigNamespaceSelector: {}
    retention: 10d
    retentionSize: ""
    tsdb:
      outOfOrderTimeWindow: 0s
    walCompression: true
    paused: false
    replicas: 1
    shards: 1
    logLevel: info
    logFormat: logfmt
    routePrefix: /
    podMetadata: {}
    podAntiAffinity: ""
    podAntiAffinityTopologyKey: kubernetes.io/hostname
    affinity: {}
    remoteRead: []
    additionalRemoteRead: []
    remoteWrite: []
    additionalRemoteWrite: []
    remoteWriteDashboards: false
    resources: {}
    storageSpec:
      volumeClaimTemplate:
        spec:
          #  storageClassName: gluster
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 50Gi
    ## Using PersistentVolumeClaim
    ##
    #  volumeClaimTemplate:
    #    spec:
    #      storageClassName: gluster
    #      accessModes: ["ReadWriteOnce"]
    #      resources:
    #        requests:
    #          storage: 50Gi
    #    selector: {}
    volumes: []
    volumeMounts: []
    additionalScrapeConfigs:
      - job_name: "telegraf"
        scrape_interval: 5s
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_container_name]
            action: keep
            regex: telegraf
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: instance
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: namespace
          - source_labels:
              [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels:
              [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__

    additionalScrapeConfigsSecret: {}
    additionalPrometheusSecretsAnnotations: {}
    additionalAlertManagerConfigs: []
    additionalAlertManagerConfigsSecret: {}
    additionalAlertRelabelConfigs: []
    additionalAlertRelabelConfigsSecret: {}
    securityContext:
      runAsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
      fsGroup: 2000
      seccompProfile:
        type: RuntimeDefault
    priorityClassName: ""
    thanos: {}
    containers: []
    initContainers: []
    portName: "http-web"
    arbitraryFSAccessThroughSMs: false
    overrideHonorLabels: false
    overrideHonorTimestamps: false
    ignoreNamespaceSelectors: false
    enforcedNamespaceLabel: ""
    prometheusRulesExcludedFromEnforce: []
    excludedFromEnforcement: []
    queryLogFile: false
    sampleLimit: false
    enforcedKeepDroppedTargets: 0
    enforcedSampleLimit: false
    enforcedTargetLimit: false
    enforcedLabelLimit: false
    enforcedLabelNameLengthLimit: false
    enforcedLabelValueLengthLimit: false
    allowOverlappingBlocks: false
    minReadySeconds: 0
    hostNetwork: false
    hostAliases: []
    tracingConfig: {}
    additionalConfig: {}
    additionalConfigString: ""
    maximumStartupDurationSeconds: 0
  additionalRulesForClusterRole: []
  additionalServiceMonitors: []
  additionalPodMonitors: []
thanosRuler:
  enabled: false
  annotations: {}
  serviceAccount:
    create: true
    name: ""
    annotations: {}
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
    maxUnavailable: ""
  ingress:
    enabled: false
    annotations: {}
    labels: {}
    hosts: []
    paths: []
    tls: []
  service:
    annotations: {}
    labels: {}
    clusterIP: ""
    port: 10902
    targetPort: 10902
    nodePort: 30905
    additionalPorts: []
    externalIPs: []
    loadBalancerIP: ""
    loadBalancerSourceRanges: []
    externalTrafficPolicy: Cluster
    type: ClusterIP
  serviceMonitor:
    selfMonitor: true
    interval: ""
    additionalLabels: {}
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    proxyUrl: ""
    scheme: ""
    tlsConfig: {}
    bearerTokenFile:
    metricRelabelings: []
    relabelings: []
    additionalEndpoints: []
  thanosRulerSpec:
    podMetadata: {}
    image:
      registry: quay.io
      repository: thanos/thanos
      tag: v0.34.1
      sha: ""
    ruleNamespaceSelector: {}
    ruleSelectorNilUsesHelmValues: true
    ruleSelector: {}
    logFormat: logfmt
    logLevel: info
    replicas: 1
    retention: 24h
    evaluationInterval: ""
    storage: {}
    alertmanagersConfig:
      existingSecret: {}
      secret: {}
    externalPrefix:
    routePrefix: /
    objectStorageConfig:
      existingSecret: {}
      secret: {}
    queryEndpoints: []
    queryConfig:
      existingSecret: {}
      secret: {}
    labels: {}
    paused: false
    additionalArgs: []
    nodeSelector: {}
    resources: {}
    podAntiAffinity: ""
    podAntiAffinityTopologyKey: kubernetes.io/hostname
    affinity: {}
    tolerations: []
    topologySpreadConstraints: []
    securityContext:
      runAsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
      fsGroup: 2000
      seccompProfile:
        type: RuntimeDefault
    listenLocal: false
    containers: []
    volumes: []
    volumeMounts: []
    initContainers: []
    priorityClassName: ""
    portName: "web"
  extraSecret:
    annotations: {}
    data: {}
cleanPrometheusOperatorObjectNames: false
extraManifests: []
